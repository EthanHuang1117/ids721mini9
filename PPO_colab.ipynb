{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JowRQEGGKQ"
      },
      "source": [
        "################################################################################\n",
        "> # **Clone GitHub repository**\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IyGzuEMQF6sJ",
        "outputId": "0eaded1b-8b34-4856-ae33-bf826b55dabb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "fatal: destination path 'PPO-PyTorch' already exists and is not an empty directory.\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "################# Clone repository from github to colab session ################\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "run this section if you want to clone all the preTrained networks, logs, graph figures, gifs\n",
        "from the GitHub repository to this colab session\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "!git clone https://github.com/nikhilbarhate99/PPO-PyTorch\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrn6rpJpF8Sc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "\n",
        "run this section if you want to copy all files and folders from cloned folder (PPO-PyTorch)\n",
        "to current directory (/content/ or ./)\n",
        "\n",
        "So you can load preTrained networks and log files without changing any paths\n",
        "\n",
        "**  This will overwrite any saved networks, logs, graph figures, or gifs\n",
        "    that are created in this session before copying having the same name (or number)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "!cp -rv ./PPO-PyTorch/* ./\n",
        "\n",
        "print(\"============================================================================================\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7AbGA2F8Ut",
        "outputId": "c6921fe3-fa71-42df-e3fa-c9af7eee6aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================================================\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "\n",
        "run this section if you want to delete original cloned folder and the cloned ipynb file\n",
        "(after you have copied its contents to current directory)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "# delete original cloned folder\n",
        "!rm -r ./PPO-PyTorch\n",
        "\n",
        "# delete cloned ipynb file\n",
        "!rm ./PPO_colab.ipynb\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4VJcUT2GlJz"
      },
      "source": [
        "################################################################################\n",
        "> # **Install Dependencies**\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rbpSQTflGlAr",
        "outputId": "f4dc6cfe-8b47-44fd-9c1b-2a4e60d764a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: gymnasium[classic_control] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic_control]) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic_control]) (4.13.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic_control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic_control]) (2.6.1)\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (4.13.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[mujoco])\n",
            "  Downloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (2.37.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.12.2)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (3.1.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (3.21.0)\n",
            "Downloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.8.0 mujoco-3.3.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "############ install compatible version of OpenAI roboschool and gym ###########\n",
        "\n",
        "!pip install swig\n",
        "\n",
        "!pip install gymnasium[classic_control]\n",
        "\n",
        "!pip install gymnasium[mujoco]\n",
        "# !pip install roboschool==1.0.7 gym==0.15.4\n",
        "\n",
        "# !pip install box2d-py\n",
        "\n",
        "# !pip install Box2D\n",
        "\n",
        "# !pip install pybullet\n",
        "\n",
        "# !pip install gym[box2d]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzZairIiGQ11"
      },
      "source": [
        "################################################################################\n",
        "> # **Introduction**\n",
        "> The notebook is divided into 5 major parts :\n",
        "\n",
        "*   **Part I** : define actor-critic network and PPO algorithm\n",
        "*   **Part II** : train PPO algorithm and save network weights and log files\n",
        "*   **Part III** : load (preTrained) network weights and test PPO algorithm\n",
        "*   **Part IV** : load log files and plot graphs\n",
        "*   **Part V** : install xvbf, load (preTrained) network weights and save images for gif and then generate gif\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s37cJXAYGrTY"
      },
      "source": [
        "################################################################################\n",
        "> # **Part - I**\n",
        "\n",
        "*   define actor critic networks\n",
        "*   define PPO algorithm\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT6VUBg-F8Zm",
        "outputId": "8ea0396e-91d1-4c5e-951d-0e5ddfe49ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "Device set to : cpu\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "############################### Import libraries ###############################\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import\n",
        "# import roboschool\n",
        "import pybullet_envs\n",
        "\n",
        "\n",
        "################################## set device ##################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# set device to cpu or cuda\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "    device = torch.device('cuda:0')\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################## PPO Policy ##################################\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.state_values = []\n",
        "        self.is_terminals = []\n",
        "\n",
        "\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.state_values[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        # actor\n",
        "        if has_continuous_action_space :\n",
        "            self.actor = nn.Sequential(\n",
        "                            nn.Linear(state_dim, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, action_dim),\n",
        "                            nn.Tanh()\n",
        "                        )\n",
        "        else:\n",
        "            self.actor = nn.Sequential(\n",
        "                            nn.Linear(state_dim, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, action_dim),\n",
        "                            nn.Softmax(dim=-1)\n",
        "                        )\n",
        "\n",
        "\n",
        "        # critic\n",
        "        self.critic = nn.Sequential(\n",
        "                        nn.Linear(state_dim, 64),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(64, 64),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(64, 1)\n",
        "                    )\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample()\n",
        "        action_logprob = dist.log_prob(action)\n",
        "        state_val = self.critic(state)\n",
        "\n",
        "        return action.detach(), action_logprob.detach(), state_val.detach()\n",
        "\n",
        "\n",
        "    def evaluate(self, state, action):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "\n",
        "            # for single action continuous environments\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "\n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "\n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
        "        self.optimizer = torch.optim.Adam([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            with torch.no_grad():\n",
        "                state = torch.FloatTensor(state).to(device)\n",
        "                action, action_logprob, state_val = self.policy_old.act(state)\n",
        "\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "            self.buffer.state_values.append(state_val)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.FloatTensor(state).to(device)\n",
        "                action, action_logprob, state_val = self.policy_old.act(state)\n",
        "\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "            self.buffer.state_values.append(state_val)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "\n",
        "        # Monte Carlo estimate of returns\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "\n",
        "        # Normalizing the rewards\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "        # convert list to tensor\n",
        "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "        old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
        "\n",
        "        # calculate advantages\n",
        "        advantages = rewards.detach() - old_state_values.detach()\n",
        "\n",
        "\n",
        "        # Optimize policy for K epochs\n",
        "        for _ in range(self.K_epochs):\n",
        "\n",
        "            # Evaluating old actions and values\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "            # match state_values tensor dimensions with rewards tensor\n",
        "            state_values = torch.squeeze(state_values)\n",
        "\n",
        "            # Finding the ratio (pi_theta / pi_theta__old)\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "            # Finding Surrogate Loss\n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "            # final loss of clipped objective PPO\n",
        "            loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, rewards) - 0.01 * dist_entropy\n",
        "\n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Copy new weights into old policy\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "        # clear buffer\n",
        "        self.buffer.clear()\n",
        "\n",
        "\n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "\n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xCb_EyxF8cF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "################################# End of Part I ################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr-ZjT_CGyEi"
      },
      "source": [
        "################################################################################\n",
        "> # **Part - II**\n",
        "\n",
        "*   train PPO algorithm on environments\n",
        "*   save preTrained networks weights and log files\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY1-DzVCF8eh",
        "outputId": "b823ff89-d7c2-4c7e-8b67-7d11dd532e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "training environment name : HalfCheetah-v4\n",
            "current logging run number for HalfCheetah-v4 :  2\n",
            "logging at : PPO_logs/HalfCheetah-v4//PPO_HalfCheetah-v4_log_2.csv\n",
            "save checkpoint path : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n",
            "max training timesteps :  100000\n",
            "max timesteps per episode :  400\n",
            "model saving frequency : 100000 timesteps\n",
            "log frequency : 800 timesteps\n",
            "printing average reward over episodes in last : 1600 timesteps\n",
            "--------------------------------------------------------------------------------------------\n",
            "state space dimension :  17\n",
            "action space dimension :  6\n",
            "--------------------------------------------------------------------------------------------\n",
            "Initializing a continuous action space policy\n",
            "--------------------------------------------------------------------------------------------\n",
            "starting std of action distribution :  1.0\n",
            "decay rate of std of action distribution :  0.05\n",
            "minimum std of action distribution :  0.1\n",
            "decay frequency of std of action distribution : 250000 timesteps\n",
            "--------------------------------------------------------------------------------------------\n",
            "PPO update frequency : 1600 timesteps\n",
            "PPO K epochs :  40\n",
            "PPO epsilon clip :  0.2\n",
            "discount factor (gamma) :  0.99\n",
            "--------------------------------------------------------------------------------------------\n",
            "optimizer learning rate actor :  0.0003\n",
            "optimizer learning rate critic :  0.001\n",
            "============================================================================================\n",
            "Started training at (GMT) :  2025-04-04 22:35:10\n",
            "============================================================================================\n",
            "Episode : 3 \t\t Timestep : 1600 \t\t Average Reward : -284.54\n",
            "Episode : 7 \t\t Timestep : 3200 \t\t Average Reward : -278.21\n",
            "Episode : 11 \t\t Timestep : 4800 \t\t Average Reward : -255.17\n",
            "Episode : 15 \t\t Timestep : 6400 \t\t Average Reward : -274.4\n",
            "Episode : 19 \t\t Timestep : 8000 \t\t Average Reward : -260.09\n",
            "Episode : 23 \t\t Timestep : 9600 \t\t Average Reward : -218.49\n",
            "Episode : 27 \t\t Timestep : 11200 \t\t Average Reward : -268.87\n",
            "Episode : 31 \t\t Timestep : 12800 \t\t Average Reward : -280.3\n",
            "Episode : 35 \t\t Timestep : 14400 \t\t Average Reward : -211.03\n",
            "Episode : 39 \t\t Timestep : 16000 \t\t Average Reward : -284.03\n",
            "Episode : 43 \t\t Timestep : 17600 \t\t Average Reward : -278.51\n",
            "Episode : 47 \t\t Timestep : 19200 \t\t Average Reward : -276.98\n",
            "Episode : 51 \t\t Timestep : 20800 \t\t Average Reward : -216.0\n",
            "Episode : 55 \t\t Timestep : 22400 \t\t Average Reward : -243.12\n",
            "Episode : 59 \t\t Timestep : 24000 \t\t Average Reward : -286.24\n",
            "Episode : 63 \t\t Timestep : 25600 \t\t Average Reward : -286.6\n",
            "Episode : 67 \t\t Timestep : 27200 \t\t Average Reward : -273.74\n",
            "Episode : 71 \t\t Timestep : 28800 \t\t Average Reward : -249.39\n",
            "Episode : 75 \t\t Timestep : 30400 \t\t Average Reward : -259.49\n",
            "Episode : 79 \t\t Timestep : 32000 \t\t Average Reward : -259.57\n",
            "Episode : 83 \t\t Timestep : 33600 \t\t Average Reward : -262.93\n",
            "Episode : 87 \t\t Timestep : 35200 \t\t Average Reward : -210.76\n",
            "Episode : 91 \t\t Timestep : 36800 \t\t Average Reward : -235.17\n",
            "Episode : 95 \t\t Timestep : 38400 \t\t Average Reward : -234.13\n",
            "Episode : 99 \t\t Timestep : 40000 \t\t Average Reward : -271.57\n",
            "Episode : 103 \t\t Timestep : 41600 \t\t Average Reward : -282.06\n",
            "Episode : 107 \t\t Timestep : 43200 \t\t Average Reward : -265.1\n",
            "Episode : 111 \t\t Timestep : 44800 \t\t Average Reward : -282.42\n",
            "Episode : 115 \t\t Timestep : 46400 \t\t Average Reward : -260.51\n",
            "Episode : 119 \t\t Timestep : 48000 \t\t Average Reward : -225.36\n",
            "Episode : 123 \t\t Timestep : 49600 \t\t Average Reward : -249.28\n",
            "Episode : 127 \t\t Timestep : 51200 \t\t Average Reward : -215.9\n",
            "Episode : 131 \t\t Timestep : 52800 \t\t Average Reward : -250.67\n",
            "Episode : 135 \t\t Timestep : 54400 \t\t Average Reward : -259.95\n",
            "Episode : 139 \t\t Timestep : 56000 \t\t Average Reward : -243.14\n",
            "Episode : 143 \t\t Timestep : 57600 \t\t Average Reward : -221.29\n",
            "Episode : 147 \t\t Timestep : 59200 \t\t Average Reward : -251.17\n",
            "Episode : 151 \t\t Timestep : 60800 \t\t Average Reward : -213.78\n",
            "Episode : 155 \t\t Timestep : 62400 \t\t Average Reward : -288.44\n",
            "Episode : 159 \t\t Timestep : 64000 \t\t Average Reward : -245.58\n",
            "Episode : 163 \t\t Timestep : 65600 \t\t Average Reward : -253.2\n",
            "Episode : 167 \t\t Timestep : 67200 \t\t Average Reward : -242.93\n",
            "Episode : 171 \t\t Timestep : 68800 \t\t Average Reward : -280.33\n",
            "Episode : 175 \t\t Timestep : 70400 \t\t Average Reward : -294.21\n",
            "Episode : 179 \t\t Timestep : 72000 \t\t Average Reward : -263.08\n",
            "Episode : 183 \t\t Timestep : 73600 \t\t Average Reward : -254.27\n",
            "Episode : 187 \t\t Timestep : 75200 \t\t Average Reward : -281.29\n",
            "Episode : 191 \t\t Timestep : 76800 \t\t Average Reward : -248.73\n",
            "Episode : 195 \t\t Timestep : 78400 \t\t Average Reward : -243.09\n",
            "Episode : 199 \t\t Timestep : 80000 \t\t Average Reward : -273.64\n",
            "Episode : 203 \t\t Timestep : 81600 \t\t Average Reward : -259.68\n",
            "Episode : 207 \t\t Timestep : 83200 \t\t Average Reward : -289.03\n",
            "Episode : 211 \t\t Timestep : 84800 \t\t Average Reward : -282.21\n",
            "Episode : 215 \t\t Timestep : 86400 \t\t Average Reward : -284.4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################################### Training ###################################\n",
        "\n",
        "\n",
        "####### initialize environment hyperparameters ######\n",
        "\n",
        "# env_name = \"CartPole-v1\"\n",
        "# has_continuous_action_space = False\n",
        "\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "has_continuous_action_space = True\n",
        "\n",
        "# this is for continuous action space\n",
        "action_std = 1.0\n",
        "action_std_decay_rate = 0.05\n",
        "min_action_std = 0.1\n",
        "action_std_decay_freq = int(1e6)\n",
        "\n",
        "\n",
        "max_ep_len = 400                    # max timesteps in one episode\n",
        "max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
        "\n",
        "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
        "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
        "save_model_freq = int(1e5)      # save model frequency (in num timesteps)\n",
        "\n",
        "\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "## Note : print/log frequencies should be > than max_ep_len\n",
        "\n",
        "\n",
        "################ PPO hyperparameters ################\n",
        "\n",
        "\n",
        "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "K_epochs = 40               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr_actor = 0.0003       # learning rate for actor network\n",
        "lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "\n",
        "print(\"training environment name : \" + env_name)\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "\n",
        "###################### logging ######################\n",
        "\n",
        "#### log files for multiple runs are NOT overwritten\n",
        "\n",
        "log_dir = \"PPO_logs\"\n",
        "if not os.path.exists(log_dir):\n",
        "      os.makedirs(log_dir)\n",
        "\n",
        "log_dir = log_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(log_dir):\n",
        "      os.makedirs(log_dir)\n",
        "\n",
        "\n",
        "#### get number of log files in log directory\n",
        "run_num = 0\n",
        "current_num_files = next(os.walk(log_dir))[2]\n",
        "run_num = len(current_num_files)\n",
        "\n",
        "\n",
        "#### create new log file for each run\n",
        "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
        "\n",
        "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
        "print(\"logging at : \" + log_f_name)\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "################### checkpointing ###################\n",
        "\n",
        "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
        "\n",
        "directory = \"PPO_preTrained\"\n",
        "if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "directory = directory + '/' + env_name + '/'\n",
        "if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"save checkpoint path : \" + checkpoint_path)\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "############# print all hyperparameters #############\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"max training timesteps : \", max_training_timesteps)\n",
        "print(\"max timesteps per episode : \", max_ep_len)\n",
        "\n",
        "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
        "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
        "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"state space dimension : \", state_dim)\n",
        "print(\"action space dimension : \", action_dim)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "if has_continuous_action_space:\n",
        "    print(\"Initializing a continuous action space policy\")\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "    print(\"starting std of action distribution : \", action_std)\n",
        "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
        "    print(\"minimum std of action distribution : \", min_action_std)\n",
        "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
        "\n",
        "else:\n",
        "    print(\"Initializing a discrete action space policy\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\")\n",
        "print(\"PPO K epochs : \", K_epochs)\n",
        "print(\"PPO epsilon clip : \", eps_clip)\n",
        "print(\"discount factor (gamma) : \", gamma)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"optimizer learning rate actor : \", lr_actor)\n",
        "print(\"optimizer learning rate critic : \", lr_critic)\n",
        "\n",
        "if random_seed:\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "    print(\"setting random seed to \", random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "    env.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "#####################################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "################# training procedure ################\n",
        "\n",
        "# initialize a PPO agent\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "\n",
        "# track total training time\n",
        "start_time = datetime.now().replace(microsecond=0)\n",
        "print(\"Started training at (GMT) : \", start_time)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# logging file\n",
        "log_f = open(log_f_name,\"w+\")\n",
        "log_f.write('episode,timestep,reward\\n')\n",
        "\n",
        "\n",
        "# printing and logging variables\n",
        "print_running_reward = 0\n",
        "print_running_episodes = 0\n",
        "\n",
        "log_running_reward = 0\n",
        "log_running_episodes = 0\n",
        "\n",
        "time_step = 0\n",
        "i_episode = 0\n",
        "\n",
        "\n",
        "# training loop\n",
        "while time_step <= max_training_timesteps:\n",
        "\n",
        "    state,_ = env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "\n",
        "        # select action with policy\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _, _= env.step(action)\n",
        "\n",
        "        # saving reward and is_terminals\n",
        "        ppo_agent.buffer.rewards.append(reward)\n",
        "        ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "        time_step +=1\n",
        "        current_ep_reward += reward\n",
        "\n",
        "        # update PPO agent\n",
        "        if time_step % update_timestep == 0:\n",
        "            ppo_agent.update()\n",
        "\n",
        "        # if continuous action space; then decay action std of ouput action distribution\n",
        "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "        # log in logging file\n",
        "        if time_step % log_freq == 0:\n",
        "\n",
        "            # log average reward till last episode\n",
        "            log_avg_reward = log_running_reward / log_running_episodes\n",
        "            log_avg_reward = round(log_avg_reward, 4)\n",
        "\n",
        "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
        "            log_f.flush()\n",
        "\n",
        "            log_running_reward = 0\n",
        "            log_running_episodes = 0\n",
        "\n",
        "        # printing average reward\n",
        "        if time_step % print_freq == 0:\n",
        "\n",
        "            # print average reward till last episode\n",
        "            print_avg_reward = print_running_reward / print_running_episodes\n",
        "            print_avg_reward = round(print_avg_reward, 2)\n",
        "\n",
        "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
        "\n",
        "            print_running_reward = 0\n",
        "            print_running_episodes = 0\n",
        "\n",
        "        # save model weights\n",
        "        if time_step % save_model_freq == 0:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"saving model at : \" + checkpoint_path)\n",
        "            ppo_agent.save(checkpoint_path)\n",
        "            print(\"model saved\")\n",
        "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        # break; if the episode is over\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    log_running_reward += current_ep_reward\n",
        "    log_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "\n",
        "\n",
        "log_f.close()\n",
        "env.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print total training time\n",
        "print(\"============================================================================================\")\n",
        "end_time = datetime.now().replace(microsecond=0)\n",
        "print(\"Started training at (GMT) : \", start_time)\n",
        "print(\"Finished training at (GMT) : \", end_time)\n",
        "print(\"Total training time  : \", end_time - start_time)\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEy2qKdZF8ha"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "################################ End of Part II ################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhK13_1G6zX"
      },
      "source": [
        "################################################################################\n",
        "> # **Part - III**\n",
        "\n",
        "*   load and test preTrained networks on environments\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZWyhkq9Gxm5",
        "outputId": "8dcca96b-ed42-4d3f-ea08-d4587b352d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "loading network from : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode: 1 \t\t Reward: -4.79\n",
            "Episode: 2 \t\t Reward: 80.49\n",
            "Episode: 3 \t\t Reward: -80.02\n",
            "Episode: 4 \t\t Reward: -14.32\n",
            "Episode: 5 \t\t Reward: 13.0\n",
            "Episode: 6 \t\t Reward: -92.45\n",
            "Episode: 7 \t\t Reward: -72.02\n",
            "Episode: 8 \t\t Reward: -79.46\n",
            "Episode: 9 \t\t Reward: -74.58\n",
            "Episode: 10 \t\t Reward: -61.23\n",
            "============================================================================================\n",
            "average test reward : -38.54\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "#################################### Testing ###################################\n",
        "\n",
        "\n",
        "################## hyperparameters ##################\n",
        "\n",
        "# env_name = \"CartPole-v1\"\n",
        "# has_continuous_action_space = False\n",
        "# max_ep_len = 400\n",
        "# action_std = None\n",
        "\n",
        "\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "has_continuous_action_space = True\n",
        "max_ep_len = 400\n",
        "action_std = 0.6\n",
        "\n",
        "# env_name = \"LunarLander-v2\"\n",
        "# has_continuous_action_space = False\n",
        "# max_ep_len = 300\n",
        "# action_std = None\n",
        "\n",
        "\n",
        "# env_name = \"BipedalWalker-v2\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1500           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "\n",
        "# env_name = \"RoboschoolWalker2d-v1\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1000           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "\n",
        "total_test_episodes = 10    # total num of testing episodes\n",
        "\n",
        "K_epochs = 80               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr_actor = 0.0003           # learning rate for actor\n",
        "lr_critic = 0.001           # learning rate for critic\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "# initialize a PPO agent\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "\n",
        "# preTrained weights directory\n",
        "\n",
        "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
        "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
        "\n",
        "\n",
        "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"loading network from : \" + checkpoint_path)\n",
        "\n",
        "ppo_agent.load(checkpoint_path)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "test_running_reward = 0\n",
        "\n",
        "for ep in range(1, total_test_episodes+1):\n",
        "    ep_reward = 0\n",
        "    state,_ = env.reset()\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _, _ = env.step(action)\n",
        "        ep_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "\n",
        "    test_running_reward +=  ep_reward\n",
        "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
        "    ep_reward = 0\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "avg_test_reward = test_running_reward / total_test_episodes\n",
        "avg_test_reward = round(avg_test_reward, 2)\n",
        "print(\"average test reward : \" + str(avg_test_reward))\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "n6IYC_JCGxlB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "################################ End of Part III ###############################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZewQELovHFt4"
      },
      "source": [
        "################################################################################\n",
        "> # **Part - IV**\n",
        "\n",
        "*   load log files using pandas\n",
        "*   plot graph using matplotlib\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "bY-E5HGcGxiu",
        "outputId": "ba055a4d-1ac4-4718-dd66-c77f1ee3c05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "loading data from : PPO_logs/HalfCheetah-v4//PPO_HalfCheetah-v4_log_0.csv\n",
            "data shape :  (125, 3)\n",
            "--------------------------------------------------------------------------------------------\n",
            "============================================================================================\n",
            "figure saved at :  PPO_figs/HalfCheetah-v4//PPO_HalfCheetah-v4_fig_0ECE590.png\n",
            "============================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "#env_name = 'CartPole-v1'\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "\n",
        "fig_num = 0     #### change this to prevent overwriting figures in same env_name folder\n",
        "\n",
        "plot_avg = True    # plot average of all runs; else plot all runs separately\n",
        "\n",
        "fig_width = 10\n",
        "fig_height = 6\n",
        "\n",
        "\n",
        "# smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "window_len_smooth = 50\n",
        "min_window_len_smooth = 1\n",
        "linewidth_smooth = 1.5\n",
        "alpha_smooth = 1\n",
        "\n",
        "window_len_var = 5\n",
        "min_window_len_var = 1\n",
        "linewidth_var = 2\n",
        "alpha_var = 0.1\n",
        "\n",
        "\n",
        "colors = ['red', 'blue', 'green', 'orange', 'purple', 'olive', 'brown', 'magenta', 'cyan', 'crimson','gray', 'black']\n",
        "\n",
        "\n",
        "# make directory for saving figures\n",
        "figures_dir = \"PPO_figs\"\n",
        "if not os.path.exists(figures_dir):\n",
        "    os.makedirs(figures_dir)\n",
        "\n",
        "# make environment directory for saving figures\n",
        "figures_dir = figures_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(figures_dir):\n",
        "    os.makedirs(figures_dir)\n",
        "\n",
        "\n",
        "fig_save_path = figures_dir + '/PPO_' + env_name + '_fig_' + str(fig_num) + \"ECE590\" + '.png'\n",
        "\n",
        "\n",
        "# get number of log files in directory\n",
        "log_dir = \"PPO_logs\" + '/' + env_name + '/'\n",
        "\n",
        "current_num_files = next(os.walk(log_dir))[2]\n",
        "num_runs = len(current_num_files)\n",
        "\n",
        "\n",
        "all_runs = []\n",
        "\n",
        "for run_num in range(num_runs):\n",
        "\n",
        "    log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
        "    print(\"loading data from : \" + log_f_name)\n",
        "    data = pd.read_csv(log_f_name)\n",
        "    data = pd.DataFrame(data)\n",
        "\n",
        "    print(\"data shape : \", data.shape)\n",
        "\n",
        "    all_runs.append(data)\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "ax = plt.gca()\n",
        "\n",
        "if plot_avg:\n",
        "    # average all runs\n",
        "    df_concat = pd.concat(all_runs)\n",
        "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
        "    data_avg = df_concat_groupby.mean()\n",
        "\n",
        "    # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "    data_avg['reward_smooth'] = data_avg['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
        "    data_avg['reward_var'] = data_avg['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
        "\n",
        "    data_avg.plot(kind='line', x='timestep' , y='reward_smooth',ax=ax,color=colors[0],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
        "    data_avg.plot(kind='line', x='timestep' , y='reward_var',ax=ax,color=colors[0],  linewidth=linewidth_var, alpha=alpha_var)\n",
        "\n",
        "    # keep only reward_smooth in the legend and rename it\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    ax.legend([handles[0]], [\"reward_avg_\" + str(len(all_runs)) + \"_runs\"], loc=2)\n",
        "\n",
        "\n",
        "else:\n",
        "    for i, run in enumerate(all_runs):\n",
        "        # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "        run['reward_smooth_' + str(i)] = run['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
        "        run['reward_var_' + str(i)] = run['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
        "\n",
        "        # plot the lines\n",
        "        run.plot(kind='line', x='timestep' , y='reward_smooth_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
        "        run.plot(kind='line', x='timestep' , y='reward_var_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_var, alpha=alpha_var)\n",
        "\n",
        "    # keep alternate elements (reward_smooth_i) in the legend\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    new_handles = []\n",
        "    new_labels = []\n",
        "    for i in range(len(handles)):\n",
        "        if(i%2 == 0):\n",
        "            new_handles.append(handles[i])\n",
        "            new_labels.append(labels[i])\n",
        "    ax.legend(new_handles, new_labels, loc=2)\n",
        "\n",
        "\n",
        "\n",
        "# ax.set_yticks(np.arange(0, 1800, 200))\n",
        "# ax.set_xticks(np.arange(0, int(4e6), int(5e5)))\n",
        "\n",
        "\n",
        "ax.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
        "\n",
        "ax.set_xlabel(\"Timesteps\", fontsize=12)\n",
        "ax.set_ylabel(\"Rewards\", fontsize=12)\n",
        "\n",
        "plt.title(env_name, fontsize=14)\n",
        "\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(fig_width, fig_height)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "plt.savefig(fig_save_path)\n",
        "print(\"figure saved at : \", fig_save_path)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaWPRW9EGxgH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "################################ End of Part IV ################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8uG43MtHNGC"
      },
      "source": [
        "################################################################################\n",
        "> # **Part - V**\n",
        "\n",
        "*   install virtual display libraries for rendering on colab / remote server ^\n",
        "*   load preTrained networks and save images for gif\n",
        "*   generate and save gif from previously saved images\n",
        "\n",
        "*   ^ If running locally; do not install xvbf and pyvirtualdisplay. Just comment out the virtual display code and render it normally.\n",
        "*   ^ You will still require to use ipythondisplay, if you want to render it in the Jupyter Notebook.\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VL3tpKf3HLAq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#### to render on colab / server / headless machine install virtual display libraries\n",
        "\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y xvfb"
      ],
      "metadata": {
        "id": "RLhLOO713mfa",
        "outputId": "5328eb11-d7d6-43ab-87c5-7120239612e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,812 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,686 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,148 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,775 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,978 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,092 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Fetched 30.0 MB in 5s (6,201 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 7,817 kB of archives.\n",
            "After this operation, 12.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.14 [29.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.14 [866 kB]\n",
            "Fetched 7,817 kB in 1s (5,629 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 126213 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.14_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.14_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "j5Rx_IFKHK-D",
        "outputId": "36d5981c-9289-42df-8778-327a2597775b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "loading network from : PPO_preTrained/HalfCheetah-v4/PPO_HalfCheetah-v4_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:519: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1 \t\t Reward: -136.66\n",
            "============================================================================================\n",
            "total number of frames / timesteps / images saved :  400\n",
            "average test reward : -136.66\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "############################# save images for gif ##############################\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import gymnasium as gym\n",
        "#import roboschool\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "One frame corresponding to each timestep is saved in a folder :\n",
        "\n",
        "PPO_gif_images/env_name/000001.jpg\n",
        "PPO_gif_images/env_name/000002.jpg\n",
        "PPO_gif_images/env_name/000003.jpg\n",
        "...\n",
        "...\n",
        "...\n",
        "\n",
        "\n",
        "if this section is run multiple times or for multiple episodes for the same env_name;\n",
        "then the saved images will be overwritten.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### beginning of virtual display code section\n",
        "\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "#### end of virtual display code section\n",
        "\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################## hyperparameters ##################\n",
        "\n",
        "# env_name = \"CartPole-v1\"\n",
        "# has_continuous_action_space = False\n",
        "# max_ep_len = 400\n",
        "# action_std = None\n",
        "\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "has_continuous_action_space = True\n",
        "max_ep_len = 400\n",
        "action_std = 0.6\n",
        "\n",
        "# env_name = \"LunarLander-v2\"\n",
        "# has_continuous_action_space = False\n",
        "# max_ep_len = 300\n",
        "# action_std = None\n",
        "\n",
        "# env_name = \"BipedalWalker-v2\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1500           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "# env_name = \"RoboschoolWalker2d-v1\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1000           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "\n",
        "total_test_episodes = 1     # save gif for only one episode\n",
        "\n",
        "render_ipython = False      # plot the images using matplotlib and ipythondisplay before saving (slow)\n",
        "\n",
        "K_epochs = 80               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr_actor = 0.0003         # learning rate for actor\n",
        "lr_critic = 0.001         # learning rate for critic\n",
        "\n",
        "#####################################################\n",
        "\n",
        "\n",
        "env = gym.make(env_name,render_mode=\"rgb_array\")\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "\n",
        "# make directory for saving gif images\n",
        "gif_images_dir = \"PPO_gif_images\" + '/'\n",
        "if not os.path.exists(gif_images_dir):\n",
        "    os.makedirs(gif_images_dir)\n",
        "\n",
        "# make environment directory for saving gif images\n",
        "gif_images_dir = gif_images_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(gif_images_dir):\n",
        "    os.makedirs(gif_images_dir)\n",
        "\n",
        "# make directory for gif\n",
        "gif_dir = \"PPO_gifs\" + '/'\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "# make environment directory for gif\n",
        "gif_dir = gif_dir + '/' + env_name  + '/'\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "\n",
        "\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "\n",
        "# preTrained weights directory\n",
        "\n",
        "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
        "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
        "\n",
        "\n",
        "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"loading network from : \" + checkpoint_path)\n",
        "\n",
        "ppo_agent.load(checkpoint_path)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "test_running_reward = 0\n",
        "\n",
        "for ep in range(1, total_test_episodes+1):\n",
        "\n",
        "    ep_reward = 0\n",
        "    state,_ = env.reset()\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _, _= env.step(action)\n",
        "        ep_reward += reward\n",
        "\n",
        "        img = env.render()\n",
        "\n",
        "\n",
        "        #### beginning of ipythondisplay code section 1\n",
        "\n",
        "        if render_ipython:\n",
        "            plt.imshow(img)\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "            ipythondisplay.display(plt.gcf())\n",
        "\n",
        "        #### end of ipythondisplay code section 1\n",
        "\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "        img.save(gif_images_dir + '/' + str(t).zfill(6) + '.jpg')\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "\n",
        "    test_running_reward +=  ep_reward\n",
        "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
        "    ep_reward = 0\n",
        "\n",
        "\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "#### beginning of ipythondisplay code section 2\n",
        "\n",
        "if render_ipython:\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "\n",
        "#### end of ipythondisplay code section 2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "print(\"total number of frames / timesteps / images saved : \", t)\n",
        "\n",
        "avg_test_reward = test_running_reward / total_test_episodes\n",
        "avg_test_reward = round(avg_test_reward, 2)\n",
        "print(\"average test reward : \" + str(avg_test_reward))\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BoVshl_ZHK7s",
        "outputId": "4edf8be2-07cd-4669-b7b8-ff9f88408d5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "total frames in gif :  30\n",
            "total duration of gif : 4.5 seconds\n",
            "saved gif at :  PPO_gifs/HalfCheetah-v4/PPO_HalfCheetah-v4_gif_0ECE590.gif\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "######################## generate gif from saved images ########################\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "#env_name = 'CartPole-v1'\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "\n",
        "gif_num = 0     #### change this to prevent overwriting gifs in same env_name folder\n",
        "\n",
        "# adjust following parameters to get desired duration, size (bytes) and smoothness of gif\n",
        "total_timesteps = 300\n",
        "step = 10\n",
        "frame_duration = 150\n",
        "\n",
        "\n",
        "# input images\n",
        "gif_images_dir = \"PPO_gif_images/\" + env_name + '/*.jpg'\n",
        "\n",
        "\n",
        "# ouput gif path\n",
        "gif_dir = \"PPO_gifs\"\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_dir = gif_dir + '/' + env_name\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_path = gif_dir + '/PPO_' + env_name + '_gif_' + str(gif_num) + \"ECE590\"+ '.gif'\n",
        "\n",
        "\n",
        "\n",
        "img_paths = sorted(glob.glob(gif_images_dir))\n",
        "img_paths = img_paths[:total_timesteps]\n",
        "img_paths = img_paths[::step]\n",
        "\n",
        "\n",
        "print(\"total frames in gif : \", len(img_paths))\n",
        "print(\"total duration of gif : \" + str(round(len(img_paths) * frame_duration / 1000, 2)) + \" seconds\")\n",
        "\n",
        "\n",
        "\n",
        "# save gif\n",
        "img, *imgs = [Image.open(f) for f in img_paths]\n",
        "img.save(fp=gif_path, format='GIF', append_images=imgs, save_all=True, optimize=True, duration=frame_duration, loop=0)\n",
        "\n",
        "print(\"saved gif at : \", gif_path)\n",
        "\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "20d1bR8xHK5j",
        "outputId": "be1c19f6-3bac-4bb5-9017-0256f41675ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "PPO_gifs/HalfCheetah-v4/PPO_HalfCheetah-v4_gif_0ECE590.gif\t\t1.41 MB\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "############################# check gif byte size ##############################\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "# env_name = 'CartPole-v1'\n",
        "env_name = \"HalfCheetah-v4\"\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "\n",
        "gif_dir = \"PPO_gifs/\" + env_name + '/*.gif'\n",
        "\n",
        "gif_paths = sorted(glob.glob(gif_dir))\n",
        "\n",
        "for gif_path in gif_paths:\n",
        "    file_size = os.path.getsize(gif_path)\n",
        "    print(gif_path + '\\t\\t' + str(round(file_size / (1024 * 1024), 2)) + \" MB\")\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM5UIAkcGxeA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "################################# End of Part V ################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YUzQOu1HYHR"
      },
      "source": [
        "################################################################################\n",
        "\n",
        "---------------------------------------------------------------------------- That's all folks ! ----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "################################################################################"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e7JowRQEGGKQ",
        "Z4VJcUT2GlJz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}